{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYMvWILoMeyg"
      },
      "source": [
        "# MapReduce Assignment\n",
        "\n",
        "Acquire Data:\n",
        "\n",
        "For this assignment, download the Harry Potter Books data from the following link (PDF is also attached):\n",
        "\n",
        "https://ztcprep.com/library/story/Harry_Potter/Harry_Potter_(www.ztcprep.com).pdf\n",
        "\n",
        "Extract Data:\n",
        "\n",
        "Select the book which corresponds to your birth month. For birth month 8-12, divide by 2 and round up.\n",
        "\n",
        "Once you selected the book, go to page number that corresponds to your birth date (1-31) and extract next 10 pages of the book to a text file (file1.txt).\n",
        "\n",
        "Next, go to page number that corresponds to your birth year (last 2 digits). For year 2000 onwards, use 1 infront of the year number to find the page number (so year 2000 becomes 100, 2001 - 101 and so on). Extract next 10 pages into another text file (file2.txt).\n",
        "\n",
        "\n",
        "\n",
        "Write Code to analyze data:\n",
        "\n",
        "1. Write Python code and use MapReduct to count occurrences of each word in the first text file (file.txt). How many times each word is repeated?\n",
        "\n",
        "2. From the second text file (file2.txt), write Python code and use MapReduct to count how many times non-English words (names, places, spells etc.) were used. List those words and how many times each was repeated.\n",
        "\n",
        "There are multiple ways of doing this. You can use pyenchant (https://pypi.org/project/pyenchant/), pyspellchecker (https://pyspellchecker.readthedocs.io/en/latest/) or just download a list of words (http://www.gwicks.net/dictionaries.htm) and search through them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy02T5Y5NCl4"
      },
      "source": [
        "### Extracting files from big pdf to `file1.txt` and `file2.txt`\n",
        "\n",
        "\n",
        "My Birthdate is 06/05/2002 (mm/dd/yyyy) so I am going to use this book for creating both `file1.txt` and `file2.txt` : `Harry Potter and the Half Blood Prince â€“ J.K. Rowling`\n",
        "\n",
        "Note: Skip this step if you already have `file1.txt` and `file2.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMz-qwgNBYt",
        "outputId": "5ed6ddbc-8db2-463c-8dcf-b40e6c98853d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in c:\\users\\devdp\\anaconda3\\lib\\site-packages (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Z8NtctAjMXQR"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "udSfnKlUMhCE"
      },
      "outputs": [],
      "source": [
        "reader = PdfReader('input/Harry_Potter_(www.ztcprep.com).pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-mmFxU69Nl7_"
      },
      "outputs": [],
      "source": [
        "file1_pages = reader.pages[4804:4822] # pages 4084-4822 includes text for pages 6-15 for selected book which are next 10 pages of my birthdate(5)\n",
        "file2_pages = reader.pages[4957:4973] # pages 4957-4973 includes text for pages 103-112 for selected book which are next 10 pages according my birthyear(2002)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Um11fTvgN6S1"
      },
      "outputs": [],
      "source": [
        "def create_txt_from_pdf(pages, filename):\n",
        "    with open(filename,\"w\") as file:\n",
        "      file.write('\\n'.join([page.extract_text() for page in pages]))\n",
        "      print(f\"Created file: {filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgSnpP_EOnzG",
        "outputId": "5ab2f78c-eb12-40ed-d040-b8dfb91e604a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created file: input/file1.txt\n",
            "Created file: input/file2.txt\n"
          ]
        }
      ],
      "source": [
        "create_txt_from_pdf(file1_pages, \"input/file1.txt\")\n",
        "create_txt_from_pdf(file2_pages, \"input/file2.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ALwvB9TzhC"
      },
      "source": [
        "#### MapReduce Part-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbFlucw10vMs",
        "outputId": "e5e36a71-db53-4fa9-d7d0-10b7b1682543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mrjob in c:\\users\\devdp\\anaconda3\\lib\\site-packages (0.7.4)\n",
            "Requirement already satisfied: pyenchant in c:\\users\\devdp\\anaconda3\\lib\\site-packages (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\devdp\\anaconda3\\lib\\site-packages (from mrjob) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mrjob pyenchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ku62fWRAnA",
        "outputId": "59e98250-4a6a-423c-a569-5a7f94ee5bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils/wordcount.py\n"
          ]
        }
      ],
      "source": [
        "%%file utils/wordcount.py\n",
        "from mrjob.job import MRJob\n",
        "class WordCountJob(MRJob):\n",
        "     def mapper(self, _, line):\n",
        "         for word in line.split():\n",
        "            if word:\n",
        "                formatted_word = ''.join(letter for letter in word.lower() if letter.isalnum()).strip()\n",
        "                if len(formatted_word) > 0:\n",
        "                    yield(formatted_word, 1)\n",
        "\n",
        "     def reducer(self, word, counts):\n",
        "         yield(word, sum(counts))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    WordCountJob.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WnvDK0tR0b1x"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\wordcount.devdp.20241003.205209.270540\n",
            "Running step 1 of 1...\n",
            "job output is in C:\\Users\\devdp\\AppData\\Local\\Temp\\wordcount.devdp.20241003.205209.270540\\output\n",
            "Streaming final output from C:\\Users\\devdp\\AppData\\Local\\Temp\\wordcount.devdp.20241003.205209.270540\\output...\n",
            "Removing temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\wordcount.devdp.20241003.205209.270540...\n"
          ]
        }
      ],
      "source": [
        "!python utils/wordcount.py input/file1.txt > output/wordcount_output.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MapReduce Part-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyenchant in c:\\users\\devdp\\anaconda3\\lib\\site-packages (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyenchant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting utils/non_eng_wordcount.py\n"
          ]
        }
      ],
      "source": [
        "%%file utils/non_eng_wordcount.py\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "import enchant\n",
        "\n",
        "class NonEngWordCount(MRJob):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(NonEngWordCount, self).__init__(*args, **kwargs)\n",
        "        self.d = enchant.Dict(\"en_US\")\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        for word in line.split():\n",
        "            if word:\n",
        "                formatted_word = ''.join(letter for letter in word.lower() if letter.isalnum()).strip() \n",
        "                if formatted_word  and len(formatted_word) > 0 and not self.d.check(formatted_word):\n",
        "                    yield(formatted_word, 1)\n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "        yield (word, sum(counts))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    NonEngWordCount.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\non_eng_wordcount.devdp.20241003.205213.676300\n",
            "Running step 1 of 1...\n",
            "job output is in C:\\Users\\devdp\\AppData\\Local\\Temp\\non_eng_wordcount.devdp.20241003.205213.676300\\output\n",
            "Streaming final output from C:\\Users\\devdp\\AppData\\Local\\Temp\\non_eng_wordcount.devdp.20241003.205213.676300\\output...\n",
            "Removing temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\non_eng_wordcount.devdp.20241003.205213.676300...\n"
          ]
        }
      ],
      "source": [
        "!python utils/non_eng_wordcount.py input/file2.txt > output/non_eng_wordcount_output.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
