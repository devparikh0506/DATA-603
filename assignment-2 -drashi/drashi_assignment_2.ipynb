{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYMvWILoMeyg"
      },
      "source": [
        "# MapReduce Assignment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy02T5Y5NCl4"
      },
      "source": [
        "### Extracrting files from big pdf to `file1.txt` and `file2.txt`\n",
        "\n",
        "\n",
        "Birthdate 07/14/2001 \n",
        "\n",
        "Target book : `Harry Potter and the Deathly Hallows â€“ J.K. Rowling`\n",
        "\n",
        "Pages for file1 : `5966` to `5983` (pages 15 to 24 of the book)\n",
        "\n",
        "Pages for file2 : `6104` to `6120` (pages 102 to 111 of the book)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMz-qwgNBYt",
        "outputId": "5ed6ddbc-8db2-463c-8dcf-b40e6c98853d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in c:\\users\\devdp\\anaconda3\\lib\\site-packages (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z8NtctAjMXQR"
      },
      "outputs": [],
      "source": [
        "from pypdf import PdfReader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating function to filter required pages for file1 and file2 from whole pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_files(pdf, f1_start, f1_end, f2_start, f2_end):\n",
        "    reader = PdfReader(pdf)\n",
        "    f1 = reader.pages[f1_start:f1_end] \n",
        "    f2 = reader.pages[f2_start:f2_end]\n",
        "    return f1,f2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "udSfnKlUMhCE"
      },
      "outputs": [],
      "source": [
        "f1,f2 = generate_files('Harry_Potter_(www.ztcprep.com).pdf', 5966,5983,6104,9120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating file1 and file2 from obtained pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Um11fTvgN6S1"
      },
      "outputs": [],
      "source": [
        "def generate_txt_files(mapping):\n",
        "    for filename in mapping:\n",
        "      with open(filename,\"w\") as file:\n",
        "        file.write(' '.join([page.extract_text() for page in mapping[filename]]))\n",
        "        print(f\"Created file: {filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Created file: file1.txt\n",
            "Created file: file2.txt\n"
          ]
        }
      ],
      "source": [
        "generate_txt_files({'file1.txt' : f1, 'file2.txt' : f2})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Now installing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbFlucw10vMs",
        "outputId": "e5e36a71-db53-4fa9-d7d0-10b7b1682543"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mrjob in c:\\users\\devdp\\anaconda3\\lib\\site-packages (0.7.4)\n",
            "Requirement already satisfied: pyenchant in c:\\users\\devdp\\anaconda3\\lib\\site-packages (3.2.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in c:\\users\\devdp\\anaconda3\\lib\\site-packages (from mrjob) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install mrjob pyenchant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ALwvB9TzhC"
      },
      "source": [
        "#### PART 1 - Word count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a MapReduce job to count occurences of each word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9ku62fWRAnA",
        "outputId": "59e98250-4a6a-423c-a569-5a7f94ee5bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing count_words.py\n"
          ]
        }
      ],
      "source": [
        "%%file count_words.py\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "\n",
        "class CountWords(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        words = self.tokenize(line)\n",
        "        for word in words:\n",
        "            if word and len(word) > 0:\n",
        "                yield (word, 1)\n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "        total_count = sum(counts)\n",
        "        yield (word, total_count)\n",
        "\n",
        "    def tokenize(self, line):\n",
        "        return re.findall(r'\\b[a-z]+\\b', line.lower())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    CountWords.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WnvDK0tR0b1x"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\count_words.devdp.20241003.205000.312914\n",
            "Running step 1 of 1...\n",
            "job output is in C:\\Users\\devdp\\AppData\\Local\\Temp\\count_words.devdp.20241003.205000.312914\\output\n",
            "Streaming final output from C:\\Users\\devdp\\AppData\\Local\\Temp\\count_words.devdp.20241003.205000.312914\\output...\n",
            "Removing temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\count_words.devdp.20241003.205000.312914...\n"
          ]
        }
      ],
      "source": [
        "!python count_words.py file1.txt > file1_output.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### PART 2 - Non English Word Frequency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating a MapReduce job to count only valid words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing invalid_word_frequency_analyzer.py\n"
          ]
        }
      ],
      "source": [
        "%%file invalid_word_frequency_analyzer.py\n",
        "from mrjob.job import MRJob\n",
        "import re\n",
        "import enchant\n",
        "\n",
        "class InvalidWordFrequencyAnalyzer(MRJob):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(InvalidWordFrequencyAnalyzer, self).__init__(*args, **kwargs)\n",
        "        self.english_dict = enchant.Dict(\"en_US\")\n",
        "\n",
        "    def mapper(self, _, line):\n",
        "        words = self.tokenize(line.lower())\n",
        "        for word in words:\n",
        "            if self.is_valid_word(word):\n",
        "                yield (word, 1)\n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "        yield (word, sum(counts))\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        return re.findall(r'\\b\\w+\\b', text)\n",
        "\n",
        "    def is_valid_word(self, word):\n",
        "        return len(word) > 1 and not self.english_dict.check(word)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    InvalidWordFrequencyAnalyzer.run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No configs found; falling back on auto-configuration\n",
            "No configs specified for inline runner\n",
            "Creating temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\invalid_word_frequency_analyzer.devdp.20241003.205002.338273\n",
            "Running step 1 of 1...\n",
            "job output is in C:\\Users\\devdp\\AppData\\Local\\Temp\\invalid_word_frequency_analyzer.devdp.20241003.205002.338273\\output\n",
            "Streaming final output from C:\\Users\\devdp\\AppData\\Local\\Temp\\invalid_word_frequency_analyzer.devdp.20241003.205002.338273\\output...\n",
            "Removing temp directory C:\\Users\\devdp\\AppData\\Local\\Temp\\invalid_word_frequency_analyzer.devdp.20241003.205002.338273...\n"
          ]
        }
      ],
      "source": [
        "!python invalid_word_frequency_analyzer.py file2.txt > file2_output.txt"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
